{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "# Reranking for Enhanced RAG Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reranking의 주요 개념 및 단계\n",
    "\n",
    "**1. 초기 검색 (First-pass Retrieval):**\n",
    "벡터 임베딩 기반의 기본 유사도 검색(Cosine similarity 등)을 사용하여 쿼리와 유사한 문서 청크들을 빠르게 검색한다.\n",
    "이 단계는 속도는 빠르지만 정확도는 상대적으로 낮을 수 있다.\n",
    "예: FAISS, Elasticsearch, Weaviate 등을 활용하여 top-20 청크를 검색하다.\n",
    "\n",
    "**2. 문서 채점 (Scoring):**\n",
    "검색된 각 문서(또는 청크)에 대해 쿼리와의 관련성을 정밀하게 평가한다.\n",
    "단순 임베딩 유사도 대신, Cross-Encoder 또는 LLM 기반 점수 평가 모델을 사용하여 정교한 채점을 수행한다.\n",
    "Cross-Encoder: 입력으로 (query, document) 쌍을 받아 직접 관련성 점수를 출력한다.\n",
    "예: bge-reranker, ms-marco-TinyBERT, OpenAI function-calling 기반 평가 모델 등이 있다.\n",
    "\n",
    "**3. 재정렬 (Reranking):**\n",
    "점수에 따라 문서들을 내림차순으로 정렬한다.\n",
    "이 과정에서 덜 관련된 청크는 하위로 밀려나며, 최종 응답에 포함되지 않을 수 있다.\n",
    "\n",
    "**4. 선택 (Selection):**\n",
    "상위 N개의 청크(예: top-3 또는 top-5)를 최종 선택하여 LLM에 입력한다.\n",
    "선택된 문서들은 더 높은 신뢰도와 일관성을 기반으로 응답 생성에 사용된다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예시 흐름 요약\n",
    "\n",
    "[사용자 쿼리] → [초기 검색 (top-20)] → [재랭크 모델로 관련성 점수 평가] → [점수 기반 정렬] → [top-3 청크 선택] → [LLM에 전달하여 응답 생성]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import fitz\n",
    "import numpy as np\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Text from a PDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    PDF 파일에서 텍스트를 추출합니다.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): PDF 파일의 경로입니다.\n",
    "\n",
    "    Returns:\n",
    "        str: PDF에서 추출한 텍스트.\n",
    "    \"\"\"\n",
    "    # PDF 파일 열기\n",
    "    mypdf = fitz.open(pdf_path)\n",
    "    all_text = \"\"  # 추출된 텍스트를 저장할 빈 문자열 초기화\n",
    "\n",
    "    # PDF의 각 페이지를 반복하며 텍스트를 추출\n",
    "    for page_num in range(mypdf.page_count):\n",
    "        page = mypdf[page_num]                  # 페이지 객체 가져오기\n",
    "        text = page.get_text(\"text\")            # 텍스트 추출\n",
    "        all_text += text                        # 텍스트 누적\n",
    "\n",
    "    return all_text  # 전체 텍스트 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking the Extracted Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chunk_text(text, n, overlap):\n",
    "    \"\"\"\n",
    "    주어진 텍스트를 겹치는 n개의 문자 세그먼트로 청크합니다.\n",
    "\n",
    "    Args:\n",
    "    text (str): 청크할 텍스트입니다.\n",
    "    n (int): 각 청크의 문자 수입니다.\n",
    "    overlap (int): 청크 간에 겹치는 문자 수입니다.\n",
    "\n",
    "    Returns:\n",
    "    List[str]: 텍스트 청크의 목록입니다.\n",
    "    \"\"\"\n",
    "    chunks = []  # 청크를 저장할 빈 목록을 초기화합니다.\n",
    "\n",
    "    # 단계 크기 (n - 겹침)로 텍스트를 반복합니다.\n",
    "    for i in range(0, len(text), n - overlap):\n",
    "        # 청크 목록에 인덱스 i에서 i + n까지의 텍스트 청크를 추가합니다.\n",
    "        chunks.append(text[i:i + n])\n",
    "\n",
    "    return chunks  # 텍스트 청크 목록을 반환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Simple VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleVectorStore:\n",
    "    \"\"\"\n",
    "    NumPy를 사용한 간단한 벡터 스토어 구현.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the vector store.\n",
    "        \"\"\"\n",
    "        self.vectors = []\n",
    "        self.texts = []\n",
    "        self.metadata = []\n",
    "    \n",
    "    def add_item(self, text, embedding, metadata=None):\n",
    "        \"\"\"\n",
    "        벡터 스토어에 항목을 추가합니다.\n",
    "        Args:\n",
    "        text (str): 원본 텍스트입니다.\n",
    "        embedding (List[float]): 임베딩 벡터입니다.\n",
    "        metadata (dict, optional): 추가 메타데이터.\n",
    "        \"\"\"\n",
    "        self.vectors.append(np.array(embedding))\n",
    "        self.texts.append(text)\n",
    "        self.metadata.append(metadata or {})\n",
    "    \n",
    "    def similarity_search(self, query_embedding, k=5):\n",
    "        \"\"\"\n",
    "        쿼리 임베딩과 가장 유사한 항목을 찾습니다.\n",
    "\n",
    "        Args:\n",
    "        query_embedding  (List[float]): 쿼리 임베딩 벡터.\n",
    "        k (int): 반환할 결과의 개수.\n",
    "\n",
    "        Returns:\n",
    "        List[Dict]: 텍스트와 메타데이터가 가장 유사한 상위 k개 항목입니다.\n",
    "        \"\"\"\n",
    "        if not self.vectors:\n",
    "            return []\n",
    "        \n",
    "        # 쿼리 임베딩을 numpy 배열로 변환하기\n",
    "        query_vector = np.array(query_embedding)\n",
    "        \n",
    "        # 코사인 유사도를 사용하여 유사도 계산하기\n",
    "        similarities = []\n",
    "        for i, vector in enumerate(self.vectors):\n",
    "            similarity = np.dot(query_vector, vector) / (np.linalg.norm(query_vector) * np.linalg.norm(vector))\n",
    "            similarities.append((i, similarity))\n",
    "        \n",
    "        # 유사도 기준 정렬(내림차순)\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # 상위 k 결과 반환\n",
    "        results = []\n",
    "        for i in range(min(k, len(similarities))):\n",
    "            idx, score = similarities[i]\n",
    "            results.append({\n",
    "                \"text\": self.texts[idx],\n",
    "                \"metadata\": self.metadata[idx],\n",
    "                \"similarity\": score\n",
    "            })\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_embeddings(text, model=\"text-embedding-3-small\"):\n",
    "    \"\"\"\n",
    "    지정된 OpenAI 모델을 사용하여 지정된 텍스트에 대한 임베딩을 생성합니다.\n",
    "\n",
    "    Args:\n",
    "    text (str): 임베딩을 생성할 입력 텍스트입니다.\n",
    "    모델 (str): 임베딩을 만드는 데 사용할 모델입니다.\n",
    "\n",
    "    Returns:\n",
    "    List[float]: 임베딩 벡터입니다.\n",
    "    \"\"\"\n",
    "    # 문자열 입력을 목록으로 변환하여 문자열 입력과 목록 입력을 모두 처리합니다.\n",
    "    input_text = text if isinstance(text, list) else [text]\n",
    "\n",
    "    # 지정된 모델을 사용하여 입력 텍스트에 대한 임베딩을 생성합니다.\n",
    "    response = client.embeddings.create(\n",
    "        model=model,\n",
    "        input=input_text\n",
    "    )\n",
    "\n",
    "    # 입력이 문자열인 경우, 첫 번째 임베딩만 반환합니다.\n",
    "    if isinstance(text, str):\n",
    "        return response.data[0].embedding\n",
    "\n",
    "    # 그렇지 않으면 모든 임베딩을 벡터 목록으로 반환합니다.\n",
    "    return [item.embedding for item in response.data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_document(pdf_path, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    RAG용 문서를 처리합니다.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): PDF 파일의 경로입니다.\n",
    "        chunk_size (int): 각 청크의 크기(문자 단위).\n",
    "        chunk_overlap (int): 청크 간 중첩되는 문자 수.\n",
    "\n",
    "    Returns:\n",
    "        SimpleVectorStore: 문서 청크와 해당 임베딩이 포함된 벡터 저장소.\n",
    "    \"\"\"\n",
    "    print(\"PDF에서 텍스트를 추출합니다...\")\n",
    "    extracted_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    print(\"텍스트를 청크 단위로 분할합니다...\")\n",
    "    chunks = chunk_text(extracted_text, chunk_size, chunk_overlap)\n",
    "    print(f\"{len(chunks)}개의 텍스트 청크가 생성되었습니다.\")\n",
    "\n",
    "    print(\"각 청크에 대한 임베딩을 생성합니다...\")\n",
    "    # 효율성을 위해 모든 청크에 대해 한 번에 임베딩 생성\n",
    "    chunk_embeddings = create_embeddings(chunks)\n",
    "\n",
    "    # 벡터 저장소 생성\n",
    "    store = SimpleVectorStore()\n",
    "\n",
    "    # 벡터 저장소에 청크 추가\n",
    "    for i, (chunk, embedding) in enumerate(zip(chunks, chunk_embeddings)):\n",
    "        store.add_item(\n",
    "            text=chunk,\n",
    "            embedding=embedding,\n",
    "            metadata={\"index\": i, \"source\": pdf_path}\n",
    "        )\n",
    "\n",
    "    print(f\"총 {len(chunks)}개의 청크가 벡터 저장소에 추가되었습니다.\")\n",
    "    return store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing LLM-based Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rerank_with_llm(query, results, top_n=3, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"\n",
    "    LLM을 활용하여 검색 결과를 관련성 기준으로 재정렬합니다.\n",
    "\n",
    "    Args:\n",
    "        query (str): 사용자의 검색 질의.\n",
    "        results (List[Dict]): 초기 검색 결과 목록.\n",
    "        top_n (int): 재정렬 후 상위에 올 결과 수.\n",
    "        model (str): 관련성 평가에 사용할 LLM 모델 이름.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: 관련성 기준으로 재정렬된 상위 결과 리스트.\n",
    "    \"\"\"\n",
    "    print(f\"{len(results)}개의 문서를 LLM을 이용해 재정렬합니다...\")\n",
    "\n",
    "    scored_results = []  # 관련성 점수를 포함한 결과 저장용 리스트\n",
    "\n",
    "    # 시스템 프롬프트 정의: 관련성 평가 기준 안내\n",
    "    system_prompt = \"\"\"너는 검색어에 대한 문서 관련성을 평가하는 전문가입니다.\n",
    "주어진 쿼리에 얼마나 잘 답변하는지를 기준으로 문서를 0~10 점수로 평가하세요.\n",
    "\n",
    "평가기준:\n",
    "- 0~2점: 전혀 관련 없음\n",
    "- 3~5점: 일부 관련 있으나 직접적인 답변은 아님\n",
    "- 6~8점: 관련 있으며 부분적으로 답변함\n",
    "- 9~10점: 매우 관련 있으며 직접적인 답변을 포함함\n",
    "\n",
    "단일 숫자(0~10)만 응답하세요. 그 외 텍스트는 포함하지 마세요.\"\"\"\n",
    "\n",
    "    # 각 검색 결과에 대해 LLM을 사용한 관련성 평가 수행\n",
    "    for i, result in enumerate(results):\n",
    "        if i % 5 == 0:\n",
    "            print(f\"{i+1}/{len(results)} 문서 평가 중...\")\n",
    "\n",
    "        user_prompt = f\"\"\"Query: {query}\n",
    "\n",
    "Document:\n",
    "{result['text']}\n",
    "\n",
    "이 문서가 쿼리에 얼마나 관련 있는지 0~10 사이의 점수로 평가하세요:\"\"\"\n",
    "\n",
    "        # 모델 호출\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # 점수 추출\n",
    "        score_text = response.choices[0].message.content.strip()\n",
    "        score_match = re.search(r'\\b(10|[0-9])\\b', score_text)\n",
    "\n",
    "        if score_match:\n",
    "            score = float(score_match.group(1))\n",
    "        else:\n",
    "            print(f\"점수 추출 실패: '{score_text}' → similarity 점수 사용\")\n",
    "            score = result[\"similarity\"] * 10\n",
    "\n",
    "        scored_results.append({\n",
    "            \"text\": result[\"text\"],\n",
    "            \"metadata\": result[\"metadata\"],\n",
    "            \"similarity\": result[\"similarity\"],\n",
    "            \"relevance_score\": score\n",
    "        })\n",
    "\n",
    "    # 관련성 점수를 기준으로 정렬\n",
    "    reranked_results = sorted(scored_results, key=lambda x: x[\"relevance_score\"], reverse=True)\n",
    "\n",
    "    # 상위 top_n개만 반환\n",
    "    return reranked_results[:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Keyword-based Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rerank_with_keywords(query, results, top_n=3):\n",
    "    \"\"\"\n",
    "    키워드 매칭 및 위치 기반의 간단한 재정렬 방식\n",
    "    \n",
    "    Args:\n",
    "        query (str): 사용자의 검색 질의\n",
    "        results (List[Dict]): 초기 검색 결과 목록\n",
    "        top_n (int): 재정렬 후 반환할 결과 개수\n",
    "        \n",
    "    Returns:\n",
    "        List[Dict]: 재정렬된 결과 목록\n",
    "    \"\"\"\n",
    "    # 질의에서 중요 키워드를 추출 (길이가 3자 초과하는 단어만 선택)\n",
    "    keywords = [word.lower() for word in query.split() if len(word) > 3]\n",
    "\n",
    "    scored_results = []  # 점수를 매긴 결과를 저장할 리스트\n",
    "\n",
    "    for result in results:\n",
    "        document_text = result[\"text\"].lower()  # 문서 내용을 소문자로 변환\n",
    "\n",
    "        # 기본 점수는 벡터 유사도에서 시작 (0.5 가중치)\n",
    "        base_score = result[\"similarity\"] * 0.5\n",
    "\n",
    "        keyword_score = 0  # 키워드 관련 점수 초기화\n",
    "        for keyword in keywords:\n",
    "            if keyword in document_text:\n",
    "                # 키워드가 포함되어 있으면 0.1점 추가\n",
    "                keyword_score += 0.1\n",
    "\n",
    "                # 키워드가 문서 초반(1/4 지점 이내)에 있으면 추가로 0.1점\n",
    "                first_position = document_text.find(keyword)\n",
    "                if first_position < len(document_text) / 4:\n",
    "                    keyword_score += 0.1\n",
    "\n",
    "                # 키워드 등장 빈도에 따라 점수 추가 (최대 0.2점까지)\n",
    "                frequency = document_text.count(keyword)\n",
    "                keyword_score += min(0.05 * frequency, 0.2)\n",
    "\n",
    "        # 최종 점수는 기본 점수 + 키워드 점수\n",
    "        final_score = base_score + keyword_score\n",
    "\n",
    "        # 점수 포함 결과를 리스트에 추가\n",
    "        scored_results.append({\n",
    "            \"text\": result[\"text\"],\n",
    "            \"metadata\": result[\"metadata\"],\n",
    "            \"similarity\": result[\"similarity\"],\n",
    "            \"relevance_score\": final_score\n",
    "        })\n",
    "\n",
    "    # 관련성 점수를 기준으로 내림차순 정렬\n",
    "    reranked_results = sorted(scored_results, key=lambda x: x[\"relevance_score\"], reverse=True)\n",
    "\n",
    "    # 상위 top_n 개 결과만 반환\n",
    "    return reranked_results[:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_response(query, context, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"\n",
    "    주어진 질의(query)와 문맥(context)을 바탕으로 응답을 생성합니다.\n",
    "    \n",
    "    Args:\n",
    "        query (str): 사용자의 질문\n",
    "        context (str): 검색된 문맥 정보\n",
    "        model (str): 응답 생성을 위해 사용할 LLM 모델 이름\n",
    "        \n",
    "    Returns:\n",
    "        str: 생성된 응답 문자열\n",
    "    \"\"\"\n",
    "    # AI의 응답 방식에 대한 지침을 담은 시스템 프롬프트 정의\n",
    "    system_prompt = (\n",
    "        \"당신은 유용한 AI 비서입니다. \"\n",
    "        \"제공된 컨텍스트에 따라서만 사용자의 질문에 답변하세요. \"\n",
    "        \"문맥에서 답을 찾을 수 없는 경우 정보가 충분하지 않다고 말하세요.\"\n",
    "    )\n",
    "\n",
    "    # 사용자 프롬프트 생성: 문맥 + 질문 조합\n",
    "    user_prompt = f\"\"\"\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Question: {query}\n",
    "\n",
    "        위의 문맥에만 근거하여 포괄적인 답변을 제공해 주세요.\n",
    "    \"\"\"\n",
    "\n",
    "    # 지정된 모델을 사용하여 응답 생성\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 생성된 응답 내용을 반환\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full RAG Pipeline with Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rag_with_reranking(query, vector_store, reranking_method=\"llm\", top_n=3, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"\n",
    "    재정렬 기능을 포함한 RAG 파이프라인 전체 흐름\n",
    "    \n",
    "    Args:\n",
    "        query (str): 사용자의 질의\n",
    "        vector_store (SimpleVectorStore): 벡터 검색이 가능한 저장소\n",
    "        reranking_method (str): 재정렬 방식 ('llm' 또는 'keywords')\n",
    "        top_n (int): 재정렬 후 사용할 상위 문서 개수\n",
    "        model (str): 응답 생성을 위한 LLM 모델 이름\n",
    "        \n",
    "    Returns:\n",
    "        Dict: 질의, 문맥, 응답 및 중간 결과가 포함된 딕셔너리\n",
    "    \"\"\"\n",
    "    # 질의 임베딩 생성\n",
    "    query_embedding = create_embeddings(query)\n",
    "\n",
    "    # 초기 검색 수행 (재정렬을 위해 충분히 많이 검색, 예: 10개)\n",
    "    initial_results = vector_store.similarity_search(query_embedding, k=10)\n",
    "\n",
    "    # 재정렬 수행\n",
    "    if reranking_method == \"llm\":\n",
    "        # LLM을 활용한 관련성 기반 재정렬\n",
    "        reranked_results = rerank_with_llm(query, initial_results, top_n=top_n)\n",
    "    elif reranking_method == \"keywords\":\n",
    "        # 키워드 기반 간단한 재정렬\n",
    "        reranked_results = rerank_with_keywords(query, initial_results, top_n=top_n)\n",
    "    else:\n",
    "        # 재정렬 없이 초기 검색 결과 상위 n개 사용\n",
    "        reranked_results = initial_results[:top_n]\n",
    "\n",
    "    # 재정렬된 결과에서 문맥(context) 구성\n",
    "    context = \"\\n\\n===\\n\\n\".join([result[\"text\"] for result in reranked_results])\n",
    "\n",
    "    # 문맥을 기반으로 응답 생성\n",
    "    response = generate_response(query, context, model)\n",
    "\n",
    "    # 최종 결과 반환 (디버깅이나 로그용으로 중간 값도 포함)\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"reranking_method\": reranking_method,\n",
    "        \"initial_results\": initial_results[:top_n],\n",
    "        \"reranked_results\": reranked_results,\n",
    "        \"context\": context,\n",
    "        \"response\": response\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Reranking Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# JSON 파일에서 검증용 데이터 로드\n",
    "with open('../dataset/validation.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 검증 데이터에서 첫 번째 질문 추출\n",
    "query = data[0]['question']\n",
    "\n",
    "# 검증 데이터에서 해당 질문의 정답(참조 답변) 추출\n",
    "reference_answer = data[0]['ideal_answer']\n",
    "\n",
    "# 사용할 PDF 파일 경로 정의\n",
    "pdf_path = \"../dataset/AI_Understanding.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF에서 텍스트를 추출합니다...\n",
      "텍스트를 청크 단위로 분할합니다...\n",
      "21개의 텍스트 청크가 생성되었습니다.\n",
      "각 청크에 대한 임베딩을 생성합니다...\n",
      "총 21개의 청크가 벡터 저장소에 추가되었습니다.\n",
      "=== 검색 및 재정렬 방식 비교 ===\n",
      "\n",
      "--- [1] STANDARD RETRIEVAL ---\n",
      "\n",
      "[질문]\n",
      "AI는 우리의 생활과 업무 방식을 변화시킬 잠재력을 가지고 있을까요?\n",
      "\n",
      "[응답]\n",
      "네, AI는 우리의 생활과 업무 방식을 변화시킬 잠재력을 가지고 있습니다. AI는 비즈니스 운영을 혁신하고, 고객 관계 관리(CRM)를 향상시키며, 공급망 관리와 인적 자원(HR) 분야에서도 효율성을 높이는 데 기여하고 있습니다. 또한, AI는 마케팅 및 영업 활동을 개선하고, 금융 서비스에서 사기 탐지와 위험 관리에 활용되고 있습니다.\n",
      "\n",
      "AI의 발전은 일자리 대체에 대한 우려를 불러일으키기도 하지만, 동시에 새로운 기회를 창출하고 기존 역할을 변화시키는 긍정적인 측면도 있습니다. 인간과 AI의 협업이 활발해지면서, AI 도구는 인간의 역량을 강화하고 의사 결정을 지원하는 인사이트를 제공할 수 있습니다. \n",
      "\n",
      "또한, AI는 창의성과 혁신을 위한 도구로도 활용되며, 예술, 음악, 문학 등 다양한 분야에서 새로운 가능성을 제시하고 있습니다. 이러한 변화는 교육 및 인력 개발, 윤리적 고려 사항과 같은 다양한 측면에서의 접근이 필요하며, 인간 중심의 접근 방식을 통해 AI의 잠재력을 최대한 활용할 수 있습니다.\n",
      "\n",
      "--- [2] LLM-BASED RERANKING ---\n",
      "10개의 문서를 LLM을 이용해 재정렬합니다...\n",
      "1/10 문서 평가 중...\n",
      "6/10 문서 평가 중...\n",
      "\n",
      "[질문]\n",
      "AI는 우리의 생활과 업무 방식을 변화시킬 잠재력을 가지고 있을까요?\n",
      "\n",
      "[응답]\n",
      "네, AI는 우리의 생활과 업무 방식을 변화시킬 잠재력을 가지고 있습니다. AI는 다양한 산업 분야에서 비즈니스 운영을 혁신하여 효율성을 향상시키고, 비용을 절감하며, 의사 결정을 개선하는 데 기여하고 있습니다. 예를 들어, 고객 관계 관리(CRM)에서는 개인화된 고객 경험을 제공하고 고객 행동을 예측하여 고객 만족도를 높이고 있습니다. 공급망 관리에서는 수요 예측과 재고 관리를 통해 운영을 최적화하고 있습니다.\n",
      "\n",
      "또한, AI는 인적 자원(HR) 분야에서 채용 프로세스를 자동화하고 교육 프로그램을 개인화하여 직원 참여와 유지에 대한 인사이트를 제공합니다. 마케팅 및 영업에서는 고객 데이터를 분석하여 캠페인을 개인화하고 판매 추세를 예측하는 데 도움을 줍니다. 금융 서비스에서는 사기 탐지와 위험 관리 등 다양한 분야에서 활용되고 있습니다.\n",
      "\n",
      "AI의 발전은 일자리 대체에 대한 우려를 불러일으키기도 하지만, 동시에 새로운 기회를 창출하고 기존 역할을 변화시키는 긍정적인 측면도 있습니다. 재교육 및 업스킬링 이니셔티브를 통해 직원들이 AI와 협업할 수 있는 기술을 갖추도록 지원하는 것이 중요합니다. \n",
      "\n",
      "결국, AI는 인간의 역량을 강화하고, 창의성과 혁신을 촉진하며, 보다 공평하고 지속 가능한 미래를 만드는 데 기여할 수 있는 도구로 자리잡고 있습니다.\n",
      "\n",
      "--- [3] KEYWORD-BASED RERANKING ---\n",
      "\n",
      "[질문]\n",
      "AI는 우리의 생활과 업무 방식을 변화시킬 잠재력을 가지고 있을까요?\n",
      "\n",
      "[응답]\n",
      "네, AI는 우리의 생활과 업무 방식을 변화시킬 잠재력을 가지고 있습니다. AI는 의료 행정을 간소화하고 효율성을 개선하며 비용을 절감하는 데 기여할 수 있습니다. 또한, 사이버 보안 분야에서는 위협 탐지 및 예방, 이상 징후 탐지, 사기 탐지, 취약점 관리, 인시던트 대응 등을 통해 보안 태세를 강화하는 데 도움을 줍니다. \n",
      "\n",
      "AI는 기후 변화, 빈곤, 의료 격차와 같은 중대한 사회적 문제를 해결할 수 있는 잠재력도 가지고 있으며, 이를 통해 자원 관리와 의사결정을 개선하고 지속 가능한 개발을 지원할 수 있습니다. 이러한 변화는 AI의 혁신적인 잠재력을 활용하여 보다 혁신적이고 공평하며 지속 가능한 미래를 만드는 데 기여할 것입니다. \n",
      "\n",
      "따라서 AI는 우리의 생활과 업무 방식을 근본적으로 변화시킬 수 있는 중요한 도구로 자리잡고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# PDF 문서를 처리하여 벡터 저장소 생성\n",
    "vector_store = process_document(pdf_path)\n",
    "\n",
    "# 테스트용 질의 정의\n",
    "query = \"AI는 우리의 생활과 업무 방식을 변화시킬 잠재력을 가지고 있을까요?\"\n",
    "\n",
    "# 다양한 검색 및 재정렬 방식 비교\n",
    "print(\"=== 검색 및 재정렬 방식 비교 ===\")\n",
    "\n",
    "# 1. 기본 검색 (재정렬 없이)\n",
    "print(\"\\n--- [1] STANDARD RETRIEVAL ---\")\n",
    "standard_results = rag_with_reranking(query, vector_store, reranking_method=\"none\")\n",
    "print(f\"\\n[질문]\\n{query}\")\n",
    "print(f\"\\n[응답]\\n{standard_results['response']}\")\n",
    "\n",
    "# 2. LLM 기반 재정렬\n",
    "print(\"\\n--- [2] LLM-BASED RERANKING ---\")\n",
    "llm_results = rag_with_reranking(query, vector_store, reranking_method=\"llm\")\n",
    "print(f\"\\n[질문]\\n{query}\")\n",
    "print(f\"\\n[응답]\\n{llm_results['response']}\")\n",
    "\n",
    "# 3. 키워드 기반 재정렬\n",
    "print(\"\\n--- [3] KEYWORD-BASED RERANKING ---\")\n",
    "keyword_results = rag_with_reranking(query, vector_store, reranking_method=\"keywords\")\n",
    "print(f\"\\n[질문]\\n{query}\")\n",
    "print(f\"\\n[응답]\\n{keyword_results['response']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_reranking(query, standard_results, reranked_results, reference_answer=None):\n",
    "    \"\"\"\n",
    "    기본 검색 결과와 재정렬된 결과를 비교 평가합니다.\n",
    "    \n",
    "    Args:\n",
    "        query (str): 사용자 질의\n",
    "        standard_results (Dict): 기본 검색 방식의 결과\n",
    "        reranked_results (Dict): 재정렬된 검색 방식의 결과\n",
    "        reference_answer (str, optional): 기준이 되는 정답 (선택사항)\n",
    "        \n",
    "    Returns:\n",
    "        str: 평가 결과 텍스트\n",
    "    \"\"\"\n",
    "    # AI 평가자에게 역할을 부여하는 시스템 프롬프트 정의\n",
    "    system_prompt = \"\"\"귀하는 RAG 시스템의 전문 평가자입니다.\n",
    "    두 가지 다른 검색 방법에서 검색된 컨텍스트와 응답을 비교하세요.\n",
    "    어떤 것이 더 나은 컨텍스트와 더 정확하고 포괄적인 답변을 제공하는지 평가하세요.\"\"\"\n",
    "\n",
    "    # 비교를 위한 텍스트 구성 (문맥은 1000자까지만 표시)\n",
    "    comparison_text = f\"\"\"Query: {query}\n",
    "\n",
    "Standard Retrieval Context:\n",
    "{standard_results['context'][:1000]}... [truncated]\n",
    "\n",
    "Standard Retrieval Answer:\n",
    "{standard_results['response']}\n",
    "\n",
    "Reranked Retrieval Context:\n",
    "{reranked_results['context'][:1000]}... [truncated]\n",
    "\n",
    "Reranked Retrieval Answer:\n",
    "{reranked_results['response']}\"\"\"\n",
    "\n",
    "    # 참조 정답(reference answer)이 있다면 비교 텍스트에 포함\n",
    "    if reference_answer:\n",
    "        comparison_text += f\"\"\"\n",
    "        \n",
    "Reference Answer:\n",
    "{reference_answer}\"\"\"\n",
    "\n",
    "    # 사용자 프롬프트 구성: 어떤 방식이 더 나은지 평가 요청\n",
    "    user_prompt = f\"\"\"\n",
    "{comparison_text}\n",
    "\n",
    "제공된 검색 방법을 평가해 주세요:\n",
    "1. 더 관련성 높은 컨텍스트\n",
    "2. 더 정확한 답변\n",
    "3. 보다 포괄적인 답변\n",
    "4. 전반적인 성능 향상\n",
    "\n",
    "구체적인 예시와 함께 자세한 분석을 제공하세요.\n",
    "\"\"\"\n",
    "\n",
    "    # AI 모델을 사용하여 평가 생성\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 평가 결과 반환\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***평가 결과***\n",
      "### 평가 분석\n",
      "\n",
      "1. **더 관련성 높은 컨텍스트**:\n",
      "   - **Standard Retrieval Context**: 이 컨텍스트는 AI의 글로벌 협업, 교육 및 인력 개발, 인간 중심의 접근 방식에 대한 내용을 포함하고 있습니다. 그러나 AI가 우리의 생활과 업무 방식을 변화시키는 구체적인 예시나 산업별 적용에 대한 정보는 부족합니다.\n",
      "   - **Reranked Retrieval Context**: 이 컨텍스트는 AI의 다양한 산업 분야에서의 구체적인 적용 사례(비즈니스 운영 혁신, 고객 관계 관리, 공급망 관리 등)를 포함하고 있어, 질문에 대한 직접적인 관련성이 높습니다. AI의 실제 활용 사례를 통해 독자가 AI의 영향을 더 잘 이해할 수 있도록 돕습니다.\n",
      "\n",
      "2. **더 정확한 답변**:\n",
      "   - **Standard Retrieval Answer**: 이 답변은 AI의 잠재력에 대한 일반적인 설명을 제공하지만, 구체적인 산업별 예시가 부족하여 다소 모호하게 느껴질 수 있습니다.\n",
      "   - **Reranked Retrieval Answer**: 이 답변은 AI의 다양한 적용 분야를 구체적으로 언급하며, 각 분야에서의 변화와 이점에 대해 명확하게 설명하고 있습니다. 예를 들어, 고객 관계 관리에서의 개인화된 경험 제공, 공급망 관리에서의 최적화 등 구체적인 사례를 통해 AI의 영향을 정확하게 전달하고 있습니다.\n",
      "\n",
      "3. **보다 포괄적인 답변**:\n",
      "   - **Standard Retrieval Answer**: AI의 긍정적인 측면과 일자리 대체에 대한 우려를 언급하지만, 구체적인 산업별 변화나 AI의 다양한 활용 가능성에 대한 설명이 부족합니다.\n",
      "   - **Reranked Retrieval Answer**: 이 답변은 AI의 긍정적인 측면과 함께 일자리 대체에 대한 우려를 다루며, 재교육 및 업스킬링의 중요성을 강조합니다. 또한, AI가 창의성과 혁신을 촉진할 수 있는 도구로 자리잡을 수 있다는 점을 언급하여 포괄적인 시각을 제공합니다.\n",
      "\n",
      "4. **전반적인 성능 향상**:\n",
      "   - **Standard Retrieval**: 전반적으로 AI의 잠재력에 대한 설명이 다소 일반적이고 구체성이 떨어집니다.\n",
      "   - **Reranked Retrieval**: 이 검색 방법은 AI의 다양한 적용 분야와 그에 따른 변화, 그리고 인간과 AI의 협업을 강조하여 전반적으로 더 나은 성능을 보여줍니다. 구체적인 사례와 함께 AI의 긍정적인 영향과 우려를 균형 있게 다루고 있어, 독자가 AI의 잠재력을 보다 잘 이해할 수 있도록 돕습니다.\n",
      "\n",
      "### 결론\n",
      "Reranked Retrieval Context와 Reranked Retrieval Answer가 Standard Retrieval Context와 Answer보다 더 관련성 높고, 정확하며, 포괄적인 정보를 제공합니다. AI가 우리의 생활과 업무 방식을 변화시킬 잠재력에 대한 질문에 대해 보다 명확하고 구체적인 답변을 제시하고 있어, 전반적인 성능이 향상되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# LLM 기반 재정렬 결과가 기본 검색 결과보다 더 나은지 평가\n",
    "evaluation = evaluate_reranking(\n",
    "    query=query,  # 사용자 질의\n",
    "    standard_results=standard_results,  # 기본 검색 결과\n",
    "    reranked_results=llm_results,  # LLM 기반 재정렬 결과\n",
    "    reference_answer=reference_answer  # 참조 정답 (비교 기준)\n",
    ")\n",
    "\n",
    "# 평가 결과 출력\n",
    "print(\"\\n***평가 결과***\")\n",
    "print(evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture",
   "language": "python",
   "name": "lecture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
