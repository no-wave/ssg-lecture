{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3CxtupEqfMAS"
   },
   "source": [
    "# Sentence Transformer: 한국어 임베딩 모델 학습\n",
    "#### 작성자: 고우주"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-17 17:54:16.047631: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-17 17:54:16.050176: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-17 17:54:16.099512: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-17 17:54:17.066060: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "comet_ml version 3.43.0 is installed, but version 3.43.2 or higher is required. Please update comet_ml to the latest version to enable Comet logging with pip install 'comet-ml>=3.43.2'.\n",
      "Currently using DataParallel (DP) for multi-gpu training, while DistributedDataParallel (DDP) is recommended for faster training. See https://sbert.net/docs/sentence_transformer/training/distributed.html for more information.\n",
      "comet_ml version 3.43.0 is installed, but version 3.43.2 or higher is required. Please update comet_ml to the latest version to enable Comet logging with pip install 'comet-ml>=3.43.2'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='138' max='138' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [138/138 06:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Sts-dev Pearson Cosine</th>\n",
       "      <th>Sts-dev Spearman Cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.899343</td>\n",
       "      <td>0.898905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.913797</td>\n",
       "      <td>0.914956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.916483</td>\n",
       "      <td>0.917812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0. (필요시) 설치\n",
    "# pip install sentence-transformers datasets torch --upgrade\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. 디바이스 설정 (CUDA 사용)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. 사전학습 모델 로드\n",
    "model_name = 'nlpai-lab/KURE-v1'\n",
    "model = SentenceTransformer(model_name, device=device)\n",
    "\n",
    "# 3. KLUE-STS 데이터셋 로드 (train/validation만 제공)\n",
    "dataset = load_dataset('mteb/KLUE-STS')\n",
    "\n",
    "# 4. InputExample 리스트 생성 (score → 0~5 범위 → 0~1로 정규화)\n",
    "def to_input_examples(split: str):\n",
    "    examples = []\n",
    "    for item in dataset[split]:\n",
    "        normalized_score = float(item['score']) / 5.0\n",
    "        examples.append(\n",
    "            InputExample(\n",
    "                texts=[item['sentence1'], item['sentence2']],\n",
    "                label=normalized_score\n",
    "            )\n",
    "        )\n",
    "    return examples\n",
    "\n",
    "train_examples = to_input_examples('train')\n",
    "dev_examples = to_input_examples('validation')\n",
    "\n",
    "# 5. DataLoader 생성\n",
    "train_dataloader = DataLoader(\n",
    "    train_examples, \n",
    "    shuffle=True,  \n",
    "    batch_size=64\n",
    ")\n",
    "dev_dataloader = DataLoader(\n",
    "    dev_examples,   \n",
    "    shuffle=False, \n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "# 6. 손실함수 정의 (CosineSimilarityLoss)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "# 7. 평가기 정의 (validation set에서 Spearman 상관계수 계산)\n",
    "dev_evaluator = evaluation.EmbeddingSimilarityEvaluator.from_input_examples(\n",
    "    dev_examples, \n",
    "    name='sts-dev', \n",
    "    write_csv=True\n",
    ")\n",
    "\n",
    "# 8. Warmup 스텝 계산 (전체 학습 스텝의 10%)\n",
    "epochs = 3\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "\n",
    "# 9. 모델 학습 및 평가\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=dev_evaluator,\n",
    "    epochs=epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    evaluation_steps=1000,       # 1,000스텝마다 validation 평가\n",
    "    output_path='./fine_tuned_kure',\n",
    "    use_amp=True                 # mixed-precision optional\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Cosine similarity: 0.4747\n",
      "Cosine similarity: 0.0488\n",
      "Embedding1-1 vector: tensor([-0.0189, -0.0196,  0.0428,  ...,  0.0406,  0.0505, -0.0416],\n",
      "       device='cuda:0')\n",
      "Embedding1-2 vector: tensor([-0.0876, -0.0315,  0.0454,  ...,  0.0424,  0.0327, -0.0437],\n",
      "       device='cuda:0')\n",
      "Embedding2-1 vector: tensor([-0.0189, -0.0196,  0.0428,  ...,  0.0406,  0.0505, -0.0416],\n",
      "       device='cuda:0')\n",
      "Embedding2-2 vector: tensor([-0.0876, -0.0315,  0.0454,  ...,  0.0424,  0.0327, -0.0437],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# 1. 디바이스 설정 (CUDA 사용 권장)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. 파인튜닝된 모델 로드\n",
    "model_path = './fine_tuned_kure'  # 학습 시 output_path와 동일한 경로\n",
    "model = SentenceTransformer(model_path, device=device)\n",
    "\n",
    "# 3. 테스트용 문장 입력\n",
    "sentences1 = [\n",
    "    \"이 문장은 모델 테스트를 위한 첫 번째 문장입니다.\",\n",
    "    \"두 번째 문장으로 모델 추론 성능을 확인합니다.\"\n",
    "]\n",
    "\n",
    "sentences2 = [\n",
    "    \"RAG는 생성 AI에서 가장 많이 사용하는 서비스입니다.\",\n",
    "    \"청킹, 임베딩, 벡터스토어, 유사검색, 참조 생성 절차를 따릅니다.\"\n",
    "]\n",
    "\n",
    "# 4. 임베딩 계산\n",
    "#    - convert_to_tensor=True 로 하면 GPU 텐서로 바로 반환됩니다.\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "# 5. 코사인 유사도 계산\n",
    "cos_sim1 = util.cos_sim(embeddings1[0], embeddings1[1])\n",
    "print(f\"Cosine similarity: {cos_sim1.item():.4f}\")\n",
    "\n",
    "cos_sim2 = util.cos_sim(embeddings2[0], embeddings2[1])\n",
    "print(f\"Cosine similarity: {cos_sim2.item():.4f}\")\n",
    "\n",
    "# 6. (선택) 개별 임베딩 벡터 확인\n",
    "print(\"Embedding1-1 vector:\", embeddings1[0])\n",
    "print(\"Embedding1-2 vector:\", embeddings1[1])\n",
    "\n",
    "print(\"Embedding2-1 vector:\", embeddings1[0])\n",
    "print(\"Embedding2-2 vector:\", embeddings1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lecture",
   "language": "python",
   "name": "lecture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
