{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG를 위한 5가지 청킹 전략\n",
    "1. 고정 크기 분할 (Fixed-size chunking)\n",
    "2. 의미 기반 분할 (Semantic Chunking)\n",
    "3. 재귀적 분할 (Recursive chunking)\n",
    "4. 문서 구조 기반 분할 (Document structure-based chunking)\n",
    "5. LLM 기반 분할 (LLM-based chunking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6S1W0gc1HHCM"
   },
   "source": [
    "## 1. 라이브러리 임포트 및 초기 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uJQPgin7HHCM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/kubwa/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "# OpenAI 클라이언트 초기화\n",
    "client = OpenAI()\n",
    "\n",
    "# NLTK 문장 토크나이저 다운로드 (최초 1회만 필요)\n",
    "nltk.download('punkt')\n",
    "\n",
    "# 헬퍼 함수: 결과 출력용\n",
    "def print_chunks(strategy_name, chunks):\n",
    "    \"\"\"결과를 출력하는 함수\"\"\"\n",
    "    print(\"=\"*20, f\"전략 {strategy_name} 결과\", \"=\"*20)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if isinstance(chunk, dict):\n",
    "            print(f\"[{i+1}번 청크]\\n내용: {chunk['content']}\\n메타데이터: {chunk['metadata']}\\n\" + \"-\"*50)\n",
    "        else:\n",
    "            print(f\"[{i+1}번 청크]\\n{chunk}\\n\" + \"-\"*50)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pvtByicHHCN"
   },
   "source": [
    "## 2. 샘플 데이터 정의\n",
    "\n",
    "모든 예제에서 사용할 텍스트와 마크다운 데이터를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uN843B-zHHCN"
   },
   "outputs": [],
   "source": [
    "# 일반 텍스트 샘플\n",
    "sample_text = \"\"\"\n",
    "인공지능(AI)은 컴퓨터가 인간과 유사한 방식으로 생각하고, 학습하고, 문제를 해결할 수 있도록 하는 기술입니다. AI는 머신러닝, 딥러닝, 자연어 처리 등 다양한 하위 분야를 포함합니다.\n",
    "\n",
    "머신러닝은 데이터로부터 패턴을 학습하여 예측이나 결정을 내리는 알고리즘을 연구하는 분야입니다. 예를 들어, 스팸 메일 필터는 머신러닝을 사용하여 원치 않는 이메일을 식별합니다.\n",
    "\n",
    "딥러닝은 인공 신경망, 특히 심층 신경망을 사용하여 복잡한 패턴을 학습하는 머신러닝의 한 종류입니다. 이미지 인식, 음성 인식 등에서 뛰어난 성능을 보입니다. 딥러닝 모델인 GPT는 자연어 생성에 널리 사용됩니다.\n",
    "\n",
    "자연어 처리(NLP)는 컴퓨터가 인간의 언어를 이해하고, 해석하고, 생성할 수 있도록 하는 AI의 한 분야입니다. 챗봇, 번역기, 감성 분석 등이 NLP의 대표적인 응용 사례입니다.\n",
    "\"\"\"\n",
    "\n",
    "# 마크다운 형식 샘플\n",
    "sample_markdown = \"\"\"\n",
    "# RAG 파이프라인의 이해\n",
    "\n",
    "## 1. 검색 (Retrieval)\n",
    "검색 단계는 사용자의 질문과 가장 관련성이 높은 문서를 벡터 데이터베이스에서 찾는 과정입니다. 임베딩 모델을 사용하여 질문과 문서를 벡터로 변환하고, 코사인 유사도를 통해 관련성을 계산합니다.\n",
    "\n",
    "## 2. 증강 (Augmentation)\n",
    "증강 단계에서는 검색된 문서를 프롬프트에 추가하여 LLM에 전달할 컨텍스트를 보강합니다. 이 과정을 통해 LLM은 더 정확하고 풍부한 답변을 생성할 수 있습니다.\n",
    "\n",
    "## 3. 생성 (Generation)\n",
    "생성 단계에서 LLM은 증강된 프롬프트를 바탕으로 최종 답변을 생성합니다. 검색된 외부 지식을 활용하므로, 환각(Hallucination) 현상을 크게 줄일 수 있습니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C49GWePYHHCN"
   },
   "source": [
    "## 전략 1: 고정 크기 분할 (Fixed-size chunking)\n",
    "\n",
    "단순히 텍스트를 정해진 크기로 자르는 방식입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gCJGhFSoHHCN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== 전략 1: 고정 크기 분할 결과 ====================\n",
      "[1번 청크]\n",
      "\n",
      "인공지능(AI)은 컴퓨터가 인간과 유사한 방식으로 생각하고, 학습하고, 문제를 해결할 수 있도록 하는 기술입니다. AI는 머신러닝, 딥러닝, 자연어 처리 등 다양한 하위 분야를 포함합니다.\n",
      "\n",
      "머신러닝은 데이터로부터 패턴을 학습하여 예측이나 결정을 내리는 알고리즘을 연\n",
      "--------------------------------------------------\n",
      "[2번 청크]\n",
      " 패턴을 학습하여 예측이나 결정을 내리는 알고리즘을 연구하는 분야입니다. 예를 들어, 스팸 메일 필터는 머신러닝을 사용하여 원치 않는 이메일을 식별합니다.\n",
      "\n",
      "딥러닝은 인공 신경망, 특히 심층 신경망을 사용하여 복잡한 패턴을 학습하는 머신러닝의 한 종류입니다. 이미지 인\n",
      "--------------------------------------------------\n",
      "[3번 청크]\n",
      " 패턴을 학습하는 머신러닝의 한 종류입니다. 이미지 인식, 음성 인식 등에서 뛰어난 성능을 보입니다. 딥러닝 모델인 GPT는 자연어 생성에 널리 사용됩니다.\n",
      "\n",
      "자연어 처리(NLP)는 컴퓨터가 인간의 언어를 이해하고, 해석하고, 생성할 수 있도록 하는 AI의 한 분야입니\n",
      "--------------------------------------------------\n",
      "[4번 청크]\n",
      " 해석하고, 생성할 수 있도록 하는 AI의 한 분야입니다. 챗봇, 번역기, 감성 분석 등이 NLP의 대표적인 응용 사례입니다.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fixed_size_chunking(text, chunk_size, chunk_overlap):\n",
    "    \"\"\"고정 크기 청킹 구현\"\"\"\n",
    "    chunks = []\n",
    "    start_index = 0\n",
    "    while start_index < len(text):\n",
    "        end_index = start_index + chunk_size\n",
    "        chunks.append(text[start_index:end_index])\n",
    "        start_index += chunk_size - chunk_overlap\n",
    "    return chunks\n",
    "\n",
    "chunks_1 = fixed_size_chunking(sample_text, chunk_size=150, chunk_overlap=30)\n",
    "print_chunks(\"1: 고정 크기 분할\", chunks_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8meCZ7NSHHCO"
   },
   "source": [
    "## 전략 2: 의미 기반 분할 (Semantic Chunking)\n",
    "\n",
    "문장 임베딩 간의 코사인 유사도를 기반으로 의미적으로 연결된 문장들을 하나의 청크로 묶습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LRV6SjNfHHCO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== 전략 2: 의미 기반 분할 결과 ====================\n",
      "[1번 청크]\n",
      "\n",
      "인공지능(AI)은 컴퓨터가 인간과 유사한 방식으로 생각하고, 학습하고, 문제를 해결할 수 있도록 하는 기술입니다. AI는 머신러닝, 딥러닝, 자연어 처리 등 다양한 하위 분야를 포함합니다. 머신러닝은 데이터로부터 패턴을 학습하여 예측이나 결정을 내리는 알고리즘을 연구하는 분야입니다. 예를 들어, 스팸 메일 필터는 머신러닝을 사용하여 원치 않는 이메일을 식별합니다. 딥러닝은 인공 신경망, 특히 심층 신경망을 사용하여 복잡한 패턴을 학습하는 머신러닝의 한 종류입니다.\n",
      "--------------------------------------------------\n",
      "[2번 청크]\n",
      "이미지 인식, 음성 인식 등에서 뛰어난 성능을 보입니다.\n",
      "--------------------------------------------------\n",
      "[3번 청크]\n",
      "딥러닝 모델인 GPT는 자연어 생성에 널리 사용됩니다. 자연어 처리(NLP)는 컴퓨터가 인간의 언어를 이해하고, 해석하고, 생성할 수 있도록 하는 AI의 한 분야입니다. 챗봇, 번역기, 감성 분석 등이 NLP의 대표적인 응용 사례입니다.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_embeddings(texts, model=\"text-embedding-3-small\"):\n",
    "    \"\"\"OpenAI API를 사용하여 텍스트 목록의 임베딩을 가져오는 함수\"\"\"\n",
    "    response = client.embeddings.create(input=texts, model=model)\n",
    "    return [np.array(item.embedding) for item in response.data]\n",
    "\n",
    "def custom_cosine_similarity(vec1, vec2):\n",
    "    \"\"\"두 벡터 간의 코사인 유사도를 계산합니다.\"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "def semantic_chunking(text, similarity_threshold=0.3):\n",
    "    \"\"\"의미 기반 청킹 구현\"\"\"\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    if not sentences:\n",
    "        return []\n",
    "\n",
    "    embeddings = get_embeddings(sentences)\n",
    "    chunks = []\n",
    "    current_chunk_sentences = [sentences[0]]\n",
    "\n",
    "    for i in range(len(sentences) - 1):\n",
    "        similarity = custom_cosine_similarity(embeddings[i], embeddings[i+1])\n",
    "        if similarity >= similarity_threshold:\n",
    "            current_chunk_sentences.append(sentences[i+1])\n",
    "        else:\n",
    "            chunks.append(\" \".join(current_chunk_sentences))\n",
    "            current_chunk_sentences = [sentences[i+1]]\n",
    "\n",
    "    chunks.append(\" \".join(current_chunk_sentences))\n",
    "    return chunks\n",
    "\n",
    "chunks_2 = semantic_chunking(sample_text)\n",
    "print_chunks(\"2: 의미 기반 분할\", chunks_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tIhox6BHHCO"
   },
   "source": [
    "## 전략 3: 재귀적 분할 (Recursive chunking)\n",
    "\n",
    "`\\n\\n`, `\\n`, `     ` 등 구분자 목록을 순서대로 적용해 계층적으로 텍스트를 나눕니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WR-CaNMKHHCO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== 전략 3: 재귀적 분할 결과 ====================\n",
      "[1번 청크]\n",
      "\n",
      "인공지능(AI)은 컴퓨터가 인간과 유사한 방식으로 생각하고, 학습하고, 문제를 해결할 수 있도록 하는 기술입니다. AI는 머신러닝, 딥러닝, 자연어 처리 등 다양한 하위 분야를 포함합니다.\n",
      "--------------------------------------------------\n",
      "[2번 청크]\n",
      "머신러닝은 데이터로부터 패턴을 학습하여 예측이나 결정을 내리는 알고리즘을 연구하는 분야입니다. 예를 들어, 스팸 메일 필터는 머신러닝을 사용하여 원치 않는 이메일을 식별합니다.\n",
      "--------------------------------------------------\n",
      "[3번 청크]\n",
      "딥러닝은 인공 신경망, 특히 심층 신경망을 사용하여 복잡한 패턴을 학습하는 머신러닝의 한 종류입니다. 이미지 인식, 음성 인식 등에서 뛰어난 성능을 보입니다. 딥러닝 모델인 GPT는 자연어 생성에 널리 사용됩니다.\n",
      "--------------------------------------------------\n",
      "[4번 청크]\n",
      "자연어 처리(NLP)는 컴퓨터가 인간의 언어를 이해하고, 해석하고, 생성할 수 있도록 하는 AI의 한 분야입니다. 챗봇, 번역기, 감성 분석 등이 NLP의 대표적인 응용 사례입니다.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def recursive_chunking(text, separators, chunk_size):\n",
    "    \"\"\"순수 Python으로 재귀적 청킹 구현\"\"\"\n",
    "    final_chunks = []\n",
    "    primary_chunks = text.split(separators[0])\n",
    "\n",
    "    for chunk in primary_chunks:\n",
    "        if len(chunk) > chunk_size and len(separators) > 1:\n",
    "            sub_chunks = recursive_chunking(chunk, separators[1:], chunk_size)\n",
    "            final_chunks.extend(sub_chunks)\n",
    "        else:\n",
    "            if chunk.strip():\n",
    "                final_chunks.append(chunk)\n",
    "    return final_chunks\n",
    "\n",
    "chunks_3 = recursive_chunking(sample_text, separators=[\"\\n\\n\", \"\\n\", \" \"], chunk_size=200)\n",
    "print_chunks(\"3: 재귀적 분할\", chunks_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpJCu_uBHHCO"
   },
   "source": [
    "## 전략 4: 문서 구조 기반 분할 (Document structure-based chunking)\n",
    "\n",
    "마크다운의 제목 (`#`, `##`)과 같은 문서의 구조를 기준으로 청크를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "iT5wlIocHHCO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== 전략 4: 문서 구조 기반 분할 결과 ====================\n",
      "[1번 청크]\n",
      "내용: # RAG 파이프라인의 이해\n",
      "\n",
      "메타데이터: {'Header 1': 'RAG 파이프라인의 이해'}\n",
      "--------------------------------------------------\n",
      "[2번 청크]\n",
      "내용: ## 1. 검색 (Retrieval)\n",
      "검색 단계는 사용자의 질문과 가장 관련성이 높은 문서를 벡터 데이터베이스에서 찾는 과정입니다. 임베딩 모델을 사용하여 질문과 문서를 벡터로 변환하고, 코사인 유사도를 통해 관련성을 계산합니다.\n",
      "메타데이터: {'Header 2': '1. 검색 (Retrieval)'}\n",
      "--------------------------------------------------\n",
      "[3번 청크]\n",
      "내용: ## 2. 증강 (Augmentation)\n",
      "증강 단계에서는 검색된 문서를 프롬프트에 추가하여 LLM에 전달할 컨텍스트를 보강합니다. 이 과정을 통해 LLM은 더 정확하고 풍부한 답변을 생성할 수 있습니다.\n",
      "메타데이터: {'Header 2': '2. 증강 (Augmentation)'}\n",
      "--------------------------------------------------\n",
      "[4번 청크]\n",
      "내용: ## 3. 생성 (Generation)\n",
      "생성 단계에서 LLM은 증강된 프롬프트를 바탕으로 최종 답변을 생성합니다. 검색된 외부 지식을 활용하므로, 환각(Hallucination) 현상을 크게 줄일 수 있습니다.\n",
      "메타데이터: {'Header 2': '3. 생성 (Generation)'}\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def markdown_chunking(markdown_text):\n",
    "    \"\"\"정규표현식을 사용하여 마크다운 구조 기반 청킹 구현\"\"\"\n",
    "    pattern = r'(^#+\\s.*$)'\n",
    "    sections = re.split(pattern, markdown_text, flags=re.MULTILINE)\n",
    "\n",
    "    chunks = []\n",
    "    for i in range(1, len(sections), 2):\n",
    "        header = sections[i].strip()\n",
    "        content = sections[i+1].strip()\n",
    "        level = header.find(' ')\n",
    "        header_type = f\"Header {level}\"\n",
    "        chunks.append({\n",
    "            \"content\": f\"{header}\\n{content}\",\n",
    "            \"metadata\": {header_type: header.lstrip('# ').strip()}\n",
    "        })\n",
    "    return chunks\n",
    "\n",
    "chunks_4 = markdown_chunking(sample_markdown)\n",
    "print_chunks(\"4: 문서 구조 기반 분할\", chunks_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRHm0rriHHCO"
   },
   "source": [
    "## 전략 5: LLM 기반 분할 (LLM-based chunking)\n",
    "\n",
    "LLM에게 직접 프롬프트를 보내 텍스트를 의미 단위로 분할하도록 요청합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "u3N5rSThHHCO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== 전략 5: LLM 기반 분할 결과 ====================\n",
      "[1번 청크]\n",
      "인공지능(AI)은 컴퓨터가 인간과 유사한 방식으로 생각하고, 학습하고, 문제를 해결할 수 있도록 하는 기술입니다. AI는 머신러닝, 딥러닝, 자연어 처리 등 다양한 하위 분야를 포함합니다.\n",
      "--------------------------------------------------\n",
      "[2번 청크]\n",
      "머신러닝은 데이터로부터 패턴을 학습하여 예측이나 결정을 내리는 알고리즘을 연구하는 분야입니다. 예를 들어, 스팸 메일 필터는 머신러닝을 사용하여 원치 않는 이메일을 식별합니다.\n",
      "--------------------------------------------------\n",
      "[3번 청크]\n",
      "딥러닝은 인공 신경망, 특히 심층 신경망을 사용하여 복잡한 패턴을 학습하는 머신러닝의 한 종류입니다. 이미지 인식, 음성 인식 등에서 뛰어난 성능을 보입니다. 딥러닝 모델인 GPT는 자연어 생성에 널리 사용됩니다.\n",
      "--------------------------------------------------\n",
      "[4번 청크]\n",
      "자연어 처리(NLP)는 컴퓨터가 인간의 언어를 이해하고, 해석하고, 생성할 수 있도록 하는 AI의 한 분야입니다. 챗봇, 번역기, 감성 분석 등이 NLP의 대표적인 응용 사례입니다.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def llm_based_chunking(text_to_chunk):\n",
    "    \"\"\"OpenAI API를 직접 사용하여 LLM 기반 청킹 구현\"\"\"\n",
    "    system_prompt = \"You are an expert in text chunking. Your task is to split the text into semantically meaningful and self-contained chunks. Return the result as a JSON object with a single key 'chunks' containing a list of strings.\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": text_to_chunk}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        temperature=0\n",
    "    )\n",
    "    result_json = response.choices[0].message.content\n",
    "    result_dict = json.loads(result_json)\n",
    "    return result_dict.get('chunks', [])\n",
    "\n",
    "chunks_5 = llm_based_chunking(sample_text)\n",
    "print_chunks(\"5: LLM 기반 분할\", chunks_5)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lecture",
   "language": "python",
   "name": "lecture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
